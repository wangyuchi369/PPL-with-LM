# PPL-with-LM
Perplexity (PPL) is one of the most common metrics for evaluating language models. 

Therefore, we can [calculating perplexity with GPT-2](https://huggingface.co/docs/transformers/perplexity) to judge whether a sentence is in line with language model(说人话就是判断说的是不是人话:). In QA problem, it may help us select the answers that more close to people's expression habit, thus reducing the search space of following models and improving efficiency, although little accuracy may be influenced.  
